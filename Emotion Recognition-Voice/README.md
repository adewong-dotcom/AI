This application uses voice recognition to identify a person's emotion as they speak.

I am using a joint dataset that combines 4 datasets (Crema, Ravdess, Savee and Tess). It classifies the audio into 8 different emotions:
(01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised)
https://www.kaggle.com/datasets/dmitrybabko/speech-emotion-recognition-en

I am testing different approaches to see which one provides the best outcome

